{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://fortunedotcom.files.wordpress.com/2017/02/amazon.gif?w=1024\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "# AMAZON PRODUCT DATA\n",
    "------------------------------------------------------------------------------------------------------------------------------  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA SET DESCRIPTION:-\n",
    "- This dataset contains product reviews and metadata of 'Clothing, Shoes and Jewelry' category from Amazon, including 2.5 million reviews spanning May 1996 - July 2014.\n",
    "- This dataset includes reviews (ratings, text, helpfulness votes), product metadata (descriptions, category information, price, brand, and image features), and links.\n",
    "- [DATA SET LINK](https://drive.google.com/open?id=0B4Hj2axlpCcxWldiajctWmY0NG8)\n",
    "\n",
    "## FILES:-\n",
    "### 'ProductSample.json'\n",
    "- Consist of all the products in 'Clothing, Shoes and Jewelry' category from Amazon. Each product is a json file in 'ProductSample.json'(each row is a json file).\n",
    "#### FIELDS:\n",
    "- 1 Asin - ID of the product, e.g. 0000031852\n",
    "- 2 Title - name of the product\n",
    "- 3 Price - price in US dollars (at time of crawl)\n",
    "- 4 ImUrl - url of the product image\n",
    "- 5 Related - related products (also bought, also viewed, bought together, buy after viewing)\n",
    "- 6 SalesRank - sales rank information\n",
    "- 7 Brand - brand name\n",
    "- 8 Categories - list of categories the product belongs to\n",
    "\n",
    "### 'ReviewSample.json'\n",
    "- Consist of all the reviews for the products in 'Clothing, Shoes and Jewelry' category from Amazon. Each review is a json file in 'ReviewSample.json'(each row is a json file).\n",
    "#### FIELDS:\n",
    "- 1 ReviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "- 2 Asin - ID of the product, e.g. 0000013714\n",
    "- 3 Reviewer Name - name of the reviewer\n",
    "- 4 Helpful - helpfulness rating of the review, e.g. 2/3\n",
    "- 5 Review Text - text of the review\n",
    "- 6 Overall - rating of the product\n",
    "- 7 Summary - summary of the review\n",
    "- 8 Unix Review Time - time of the review (unix time)\n",
    "- 9 Review Time - time of the review (raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS:-\n",
    "* Analysis_1 : Sentimental Analysis on Reviews.\n",
    "* Analysis_2 : Exploratory Analysis.\n",
    "* Analysis_3 : 'Susan Katz' as 'Point of Interest' with maximum Reviews on Amazon.\n",
    "* Analysis_4 : 'Bundle' or 'Bought-Together' based Analysis.\n",
    "* Analysis_5 : Recommender System for Popular Brand 'Rubie's Costume Co'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DATA PROCESSING:-\n",
    "#### PRODUCT DATA i.e. ProductSample.json\n",
    "- Step 1: Reading a multiple json files from a single json file 'ProductSample.json' and appending it to the list such that each index of a list has a content of single json file.\n",
    "- Step 2: Iterating over list and loading each index as json and getting the data from the each index and making a list of Tuples containg all the data of json files. During each iteration json file is first cleaned by converting files into proper json format files by some replacements.\n",
    "- Step 3: Creating a dataframe using the list of Tuples got in the previous step.\n",
    "\n",
    "#### REVIEW DATA i.e. ReviewSample.json\n",
    "- Step 1: Reading a multiple json files from a single json file 'ReviewSample.json' and appending it to the list such that each index of a list has a content of single json file.\n",
    "- Step 2: Iterating over list and loading each index as json and getting the data from the each index and making a list of Tuples containg all the data of json files.\n",
    "- Step 3: Creating a dataframe using the list of Tuples got in the previous step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANALYSIS 1: SENTIMENTAL ANALYSIS ON REVIEWS (1999-2014)\n",
    "- Wordcloud of summary section of 'Positive' and 'Negative' Reviews on Amazon.\n",
    "- VADER (Valence Aware Dictionary and Sentiment Reasoner) Sentiment analysis tool was used to calculate the sentiment of reviews.\n",
    "- Sentiment distribution (positive, negative and neutral) across each product along with their names mapped with the product database 'ProductSample.json'.\n",
    "- List of products with most number of positive, negative and neutral Sentiment (3 Different list).\n",
    "- Percentage distribution of positive, neutral and negative in terms of sentiments.\n",
    "- Sentiment distribution across the Year.\n",
    "------\n",
    "#### WordCloud of summary section of 'Positive' and 'Negative' Reviews on Amazon.\n",
    "- Cleaning(Data Processing) was performed on 'ReviewSample.json' file and importing the data as pandas DataFrame.\n",
    "- Created a function to calculate sentiments using Vader Sentiment Analyzer and Naive Bayes Analyzer.\n",
    "- Vader Sentiment Analyzer was used at the final stage, since output given was much more faster and accurate.\n",
    "- Only taking 1 Lakh (1,00,000) reviews into consideration for Sentiment Analysis so that jupyter notebook dosen't crash.\n",
    "- Sentiment value was calculated for each review and stored in the new column 'Sentiment_Score' of DataFrame.\n",
    "- Seperated negatives and positives Sentiment_Score into different dataframes for creating a 'Wordcloud'.\n",
    "- Stemming function was created for stemming of different form of words which will be used by 'create_Word_Corpus()' function. PorterStemmer from nltk.stem was used for stemming.\n",
    "- Function 'create_Word_Corpus()' was created to generate a Word Corpus.\n",
    "###### To Generate a word corpus following steps are performed inside the function 'create_Word_Corpus(df)'\n",
    " - Step 1 :- Iterating over the 'summary' section of reviews such that we only get important content of a review.\n",
    " - Step 2 :- Converting the content into Lowercase.\n",
    " - Step 3 :- Using nltk.tokenize to get words from the content.\n",
    " - Step 4 :- Using string.punctuation to get rid of punctuations.\n",
    " - Step 5 :- Using stopwords from nltk.corpus to get rid of stopwords.\n",
    " - Step 6 :- Stemming of Words.\n",
    " - Step 7 :- Finally forming a word corpus and returning the word corpus.\n",
    "- Function 'plot_cloud()' was defined to plot cloud.\n",
    "\n",
    " ##### WordCloud of 'Summary' section of Positive Reviews.\n",
    "<img src=\"../Analysis/Analysis_1/Positive_WordCloud.png\">\n",
    " ##### WordCloud of 'Summary' section of Negative Reviews.\n",
    "<img src=\"../Analysis/Analysis_1/Negative_WordCloud.png\">\n",
    "\n",
    "#### SENTIMENT DISTRIBUTION ACROSS EACH PRODUCT ALONG WITH THEIR NAMES MAPPED FROM PRODUCT DATABASE.\n",
    "- Cleaning(Data Processing) was performed on 'ProductSample.json' file and importing the data as pandas DataFrame.\n",
    "- Took only those columns which were required further down the Analysis such as 'Asin' and 'Sentiment_Score'.\n",
    "- Used Groupby on 'Asin' and 'Sentiment_Score' calculated the count of all the products with positive, negative and neutral sentiment Score.\n",
    "- DataFrame Manipulations were performed to get desired DataFrame.\n",
    "- Sorted the rows in the ascending order of 'Asin' and assigned it to another DataFrame 'x1'.\n",
    "- Products Asin and Title is assigned to x2 which is a copy of DataFrame 'Product_datset'(Product database).\n",
    "- Merged 2 Dataframes 'x1' and 'x2' on common column 'Asin' to map product 'Title' to respective product 'Asin' using 'inner' type.\n",
    "- Took all the data such as Asin, Title, Sentiment_Score and Count into .csv file                                          \n",
    " - (path : Final/Analysis/Analysis_1/Sentiment_Distribution_Across_Product.csv)\n",
    "\n",
    "#### LIST OF PRODUCTS WITH MOST NUMBER OF POSITIVE, NEGATIVE AND NEUTRAL SENTIMENT (3 DIFFERENT LIST).\n",
    "- Segregated reviews based on their Sentiments_Score into 3 different(positive,negative and neutral) data frame,which we got earlier in step.\n",
    "- Sorted the above result in descending order of count.\n",
    "- Droped the unwanted column 'index'.\n",
    "- Took all the data such as Asin, Title, Sentiment_Score and Count for 3 into .csv file\n",
    " - (path : '../Analysis/Analysis_1/Positive_Sentiment_Max.csv'), \n",
    " - (path : '../Analysis/Analysis_1/Negative_Sentiment_Max.csv'), \n",
    " - (path : '../Analysis/Analysis_1/Neutral_Sentiment_Max.csv')\n",
    " \n",
    "#### PERCENTAGE DISTRIBUTION OF POSITIVE, NEUTRAL AND NEGATIVE IN TERMS OF SENTIMENTS.\n",
    "- Took summation of count column to get the Total count of Reviews under Consideration.\n",
    "- Percentage was calculated for positive, negative and neutral and was stored into a new column 'Percentage' of data frame.\n",
    "- Taking all the data such as Sentiment_Score, Count and Percentage into .csv file\n",
    " - (path : '../Analysis/Analysis_1/Sentiment_Percentage.csv')\n",
    " \n",
    "#### SENTIMENT DISTRIBUTION ACROSS THE YEAR\n",
    "- Converted the data type of 'Review_Time' column in the Dataframe 'Selected_Rows' to datetime format.\n",
    "- Created an Addtional column as 'Month' in Datatframe 'Selected_Rows' for Month by taking the month part of 'Review_Time' column.\n",
    "- Created an Addtional column as 'Year' in Datatframe 'Selected_Rows' for Year by taking the year part of 'Review_Time' column.\n",
    "- Grouped on the basis of 'Year' and 'Sentiment_Score' to get the respective count.\n",
    "- Segregated rows based on their Sentiments by year.\n",
    "- Got the total count including positive, negative and neutral to get the Total count of Reviews under Consideration for each year.\n",
    "- Merged the dataframe with total count to individual sentiment count to get percentage.\n",
    "- Calculated the Percentage to find a trend for sentiments.\n",
    "- Took all the data such as Year, Sentiment_Score, Count, Total_Count and Percentage for 3 into .csv file\n",
    " - (path : '../Analysis/Analysis_1/Pos_Sentiment_Percentage_vs_Year.csv')\n",
    " - (path : '../Analysis/Analysis_1/Neg_Sentiment_Percentage_vs_Year.csv')\n",
    " - (path : '../Analysis/Analysis_1/Neu_Sentiment_Percentage_vs_Year.csv')\n",
    "- Bar-Chart to know the Trend for Percentage of Positive, Negative and Neutral Review over the years based on Sentiments.\n",
    "##### Bar-Chart to know the Trend for Percentage of Positive Review over the years based on Sentiments.\n",
    "<img src=\"../Analysis/Analysis_1/Positive Reviews Over Years.png\">\n",
    "##### Bar-Chart to know the Trend for Percentage of Negative Review over the years based on Sentiments.\n",
    "<img src=\"../Analysis/Analysis_1/Negative Reviews Over Years.png\">\n",
    "##### Bar-Chart to know the Trend for Percentage of Neutral Review over the years based on Sentiments.\n",
    "<img src=\"../Analysis/Analysis_1/Neutral Reviews Over Years.png\">\n",
    "\n",
    "## CONCLUSION OF ANALYSIS 1:-\n",
    "- From Positive WordCloud \n",
    " - Popular words used to describe the products were love, perfect, nice, good, best, great and etc.\n",
    " - Many people who reviewed were happy with the price of the products sold on Amazon.\n",
    " - Much talked products were watch, bra, jacket, bag, costume, etc.\n",
    "- From Negative WordCloud\n",
    " - Popular words used to describe the products were dissapoint, badfit, terrible, defect, return and etc.\n",
    " - Much talked products were shoes, watch, bra, batteries, etc.\n",
    "- Popular product in terms of sentiments for following\n",
    " - Positive:\n",
    "  - Converse Unisex Chuck Taylor Classic Colors Sneaker, Number of positive reviews:953\n",
    "  - Converse Unisex Chuck Taylor All Star Hi Top Black Monochrome Sneaker, Number of positive reviews:932\n",
    "  - Yaktrax Walker Traction Cleats for Snow and Ice, Number of positive reviews:676\n",
    " - Negative:\n",
    "  - Yaktrax Walker Traction Cleats for Snow and Ice, Number of negative reviews:65\n",
    "  - Converse Unisex Chuck Taylor Classic Colors Sneaker, Number of negative reviews:44\n",
    "  - Converse Unisex Chuck Taylor All Star Hi Top Black Monochrome Sneaker, Number of negative reviews:44\n",
    " - Neutral:\n",
    "  - Converse Unisex Chuck Taylor Classic Colors Sneaker, Number of neutral reviews:313\n",
    "  - Yaktrax Walker Traction Cleats for Snow and Ice,Number of neutral reviews:253\n",
    "  - Converse Unisex Chuck Taylor All Star Hi Top Black Monochrome Sneaker,Number of neutral reviews:247\n",
    "- Sentiment Percentage Distribution.\n",
    "  - Positive: 72.7 %\n",
    "  - Negative: 5 %\n",
    "  - Neutral: 22.3 %\n",
    "  - Overall Sentiment for reviews on Amazon is on positive side as it has very less negative sentiments.\n",
    "- Trend for Percentage of Review over the years\n",
    " - positive reviews percentage has been pretty consistent between 70-80 throughout the years.\n",
    " - negative reviews has been decreasing lately since last three years, may be they worked on the services and faults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 2: EXPLORATORY ANALYSIS OF PRODUCT AND REVIEWS (1999-2014)\n",
    "- Number of Reviews over the years.\n",
    "- Number of Reviews by month over the years.\n",
    "- Distribution of 'Overall Rating' for 2.5 million 'Clothing Shoes and Jewellery' reviews on Amazon.\n",
    "- Yearly average 'Overall Ratings' over the years.\n",
    "- Distribution of helpfulness on 'Clothing Shoes and Jwellery' reviews on Amazon.\n",
    "- Distributution of length of reviews on Amazon.\n",
    "- Distribution of product prices of 'Clothing Shoes and Jewellery' category on Amazon.\n",
    "- Distribution of 'Overall Rating' of Amazon 'Clothing Shoes and Jewellery'.\n",
    "- Product Price V/S Overall Rating of reviews written for products.\n",
    "- Average Review Length V/S Product Price for Amazon products.\n",
    "- Distribution of 'Number of Reviews' written by each of the Amazon 'Clothing Shoes and Jewellery' user.\n",
    "- Distribution of 'Average Rating' written by each of the Amazon 'Clothing Shoes and Jewellery' users.\n",
    "- Distribution of Helpfulness of reviews written by Amazon 'Clothing Shoes and Jewellery' users.\n",
    "- Average Rating V/S Avg Helpfulness written by Amazon 'Clothing Shoes and Jewellery' user\n",
    "- Helpfulness VS Average Length of reviews written by Amazon 'Clothing Shoes and Jewellery' users.\n",
    "-----------------------------------\n",
    "#### Number of Reviews over the years.\n",
    "- Cleaning(Data Processing) was performed on 'ReviewSample.json' file and importing the data as pandas DataFrame.\n",
    "- Converting the data type of 'Review_Time' column in the Dataframe 'dataset' to datetime format.\n",
    "- Creating an Addtional column as 'Month' in Datatframe 'dataset' for Month by taking the month part of 'Review_Time' column.\n",
    "- Creating an Addtional column as 'Year' in Datatframe 'dataset' for Year by taking the year part of 'Review_Time' column\n",
    "- Grouping by year and taking the count of reviews for each year.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Year_VS_Reviews.csv')\n",
    "- Line Plot for number of reviews over the years.\n",
    "<img src=\"../Analysis/Analysis_2/NUMBER OF REVIEWS OVER THE YEARS.png\">\n",
    "\n",
    "#### Number of Reviews by month over the years.\n",
    "- Grouping on Month and getting the count.\n",
    "- Replacing digits of 'Month' column in 'Monthly' dataframe with words using 'Calendar' library.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Month_VS_Reviews.csv')\n",
    "- Line Plot for number of reviews over the years.\n",
    "<img src=\"../Analysis/Analysis_2/Number of Reviews by Month.png\">\n",
    "\n",
    "#### Distribution of 'Overall Rating' for 2.5 million 'Clothing Shoes and Jewellery' reviews on Amazon.\n",
    "- Grouping on 'Rating' and getting the count.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Rating_VS_Reviews.csv')\n",
    "- Bar Chart Plot for Distribution of Rating.\n",
    "<img src=\"../Analysis/Analysis_2/Distribution of Rating.png\">\n",
    "\n",
    "#### Yearly average 'Overall Ratings' over the years.\n",
    "- Grouping on Year and getting the mean.\n",
    "- Calculating the Moving Average ith window of '3' to confirm the trend\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Yearly_Avg_Rating.csv')\n",
    "- Bar Chart Plot for Distribution of Rating.\n",
    "<img src=\"../Analysis/Analysis_2/AVERAGE OVERALL RATINGS OVER THE YEARS.png\">\n",
    "\n",
    "#### Distribution of helpfulness on 'Clothing Shoes and Jwellery' reviews on Amazon.\n",
    "- Only taking required columns and converting their data type.\n",
    "- Calculating helpfulnes Percentage and replacing Nan with 0\n",
    "- Creating an Interval of 10 for percentage Value.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Helpfuness_Percentage_Distribution.csv')\n",
    "- Bar Chart Plot for Distribution of Rating.\n",
    "<img src=\"../Analysis/Analysis_2/Percentage distribution of helpfulness.png\">\n",
    "\n",
    "#### Distributution of length of reviews on Amazon.\n",
    "- Creating a new Data frame with 'Reviewer_ID','Reviewer_Name' and 'Review_Text' columns.\n",
    "- Counting the number of words using 'len(x.split())'\n",
    "- Counting the number of characters 'len(x)'\n",
    "- Creating an Interval of 100 for Charcters and Words Length Value.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Character_Length_Distribution.csv')\n",
    " - (path : '../Analysis/Analysis_2/Word_Length_Distribution.csv')\n",
    "- Bar Plot for distribution of Character Length of reviews on Amazon\n",
    "<img src=\"../Analysis/Analysis_2/Distribution of Character Length.png\"> \n",
    "\n",
    "- Bar Plot for distribution of Word Length of reviews on Amazon\n",
    "<img src=\"../Analysis/Analysis_2/Distribution of Word Length.png\"> \n",
    "\n",
    "#### Distribution of product prices of 'Clothing Shoes and Jewellery' category on Amazon.\n",
    "- Cleaning(Data Processing) was performed on 'ProductSample.json' file and importing the data as pandas DataFrame.\n",
    "- Segregating the product based on price range.\n",
    " - [0-10]\n",
    " - [11-50]\n",
    " - [51-100]\n",
    " - [101-200]\n",
    " - [201-500]\n",
    " - [501-1000]\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Price_Distribution.csv')\n",
    "- Bar Chart Plot for Distribution of Price.\n",
    "<img src=\"../Analysis/Analysis_2/Price Distribution.png\">\n",
    "\n",
    "#### Distribution of 'Overall Rating' of Amazon 'Clothing Shoes and Jewellery'.\n",
    "- Grouping on Asin and getting the mean of Rating.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/Rating_Distribution.csv')\n",
    "- Bar Chart Plot for Distribution of Price.\n",
    "<img src=\"../Analysis/Analysis_2/Distribution of Average Rating of Product.png\">\n",
    "\n",
    "#### Product Price V/S Overall Rating of reviews written for products.\n",
    "- Merging 2 data frame 'Product_dataset' and data frame got in above analysis, on common column 'Asin'.\n",
    "- Scatter plot for product price v/s overall rating\n",
    "<img src=\"../Analysis/Analysis_2/PRODUCT PRICE VS OVERALL RATING.png\">\n",
    "\n",
    "#### Average Review Length V/S Product Price for Amazon products.\n",
    "- Creating a new Data frame with 'Reviewer_ID','Reviewer_Name', 'Asin' and 'Review_Text' columns.\n",
    "- Counting the number of words using 'len(x.split())'\n",
    "- Counting the number of characters 'len(x)'\n",
    "- Grouped on 'Asin' and taking the mean of Word and Character length.\n",
    "- Scatter plot for product price v/s average review length.\n",
    "<img src=\"../Analysis/Analysis_2/PRODUCT PRICE VS AVERAGE REVIEW LENGTH.png\">\n",
    "\n",
    "#### Distribution of 'Number of Reviews' written by each of the Amazon 'Clothing Shoes and Jewellery' user.\n",
    "- Grouped on 'Reviewer_ID' and took the count.\n",
    "- Sorting in the descending order of number of reviews got in previous step.\n",
    "- Now grouped on Number of reviews and took the count.\n",
    "- Created a interval of 10 for plot and took the sum of all the count using groupby.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/DISTRIBUTION OF NUMBER OF REVIEWS.csv')\n",
    "- Scatter Plot for Distribution of Number of Reviews.\n",
    "<img src=\"../Analysis/Analysis_2/NUMBER OF REVIEWS WRITTEN BY EACH USER.png\">\n",
    "\n",
    "#### Distribution of 'Average Rating' written by each of the Amazon 'Clothing Shoes and Jewellery' users.\n",
    "- Grouped on 'Reviewer_ID' and took the mean of Rating.\n",
    "- Scatter Plot for Distribution of Average Rating.\n",
    "<img src=\"../Analysis/Analysis_2/Average Rating Written By User.png\">\n",
    "\n",
    "#### Distribution of Helpfulness of reviews written by Amazon 'Clothing Shoes and Jewellery' users.\n",
    "- Creating a new Dataframe with 'Reviewer_ID','helpful_UpVote' and 'Total_Votes'\n",
    "- Calculate percentage using: (helpful_UpVote/Total_Votes)*100\n",
    "- Grouped on 'Reviewer_ID' and took the mean of Percentage'\n",
    "- Created interval of 10 for percentage\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/DISTRIBUTION OF HELPFULNESS.csv')\n",
    "- Bar Chart Plot for DISTRIBUTION OF HELPFULNESS.\n",
    "<img src=\"../Analysis/Analysis_2/DISTRIBUTION OF HELPFULNESS.png\">\n",
    "\n",
    "#### Average Rating V/S Avg Helpfulness written by Amazon 'Clothing Shoes and Jewellery' user\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/AVERAGE RATING VS AVERAGE HELPFULNESS.csv')\n",
    "- Scatter Plot.\n",
    "<img src=\"../Analysis/Analysis_2/AVERAGE RATING VS AVG HELPFULNESS.png\">\n",
    "\n",
    "#### Helpfulness VS Average Length of reviews written by Amazon 'Clothing Shoes and Jewellery' users.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_2/HELPFULNESS VS AVERAGE LENGTH.csv')\n",
    "- Scatter Plot.\n",
    "<img src=\"../Analysis/Analysis_2/HELPFULNESS VS AVERAGE LENGTH.png\">\n",
    "\n",
    "\n",
    "## CONCLUSION OF ANALYSIS 3:-\n",
    "- There has been exponential growth for Amazon in terms of reviews, which also means the sales also increased exponentially. Plot for 2014 shows a drop because we only have a data uptill May and even then it is more than half for 5 months data.\n",
    "- Buyers generally shop more in December and January.\n",
    "- More than half of the reviews give a 4 or 5 star rating, with very few giving 1, 2 or 3 stars relatively.\n",
    "- Average Rating over every year for Amazon has been above 4 and also the moving average confirms the trend.\n",
    "- Majority of the reviews had perfect helpfulness scores.That would make sense; if you’re writing a review (especially a 5 star review), you’re writing with the intent to help other prospective buyers.\n",
    "- Majority of reviews on Amazon has length of 100-200 characters or 0-100 words.\n",
    "- Over 2/3rds of Amazon Clothing are priced between $0 and $50, which makes sense as clothes are not meant to be so expensive.\n",
    "- The most expensive products have 4-star and 5-star overall ratings.\n",
    "- Over 95% of the reviewers of Amazon electronics left less than 10 reviews.\n",
    "- Reviewers who give a product a 4 - 5 star rating are more passionate about the product and likely to write better reviews than someone who writes a 1 - 2 star "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 3 : POINT OF INTEREST AS THE ONE WITH MAXIMUM NUMBER OF REVIEWS ON AMAZON\n",
    "- Reviewer with maximum number of reviews.\n",
    "- Distribution of reviews for 'Susan Katz' based on overall rating (reviewer_id : A1RRMZKOMZ2M7J).\n",
    "- Distribution of reviews over the years for 'Susan Katz'.\n",
    "- Percentage distribution of negative reviews for 'Susan Katz', since the count of reviews is dropping post year 2009.\n",
    "- Lexical density distribution over the year for reviews written by 'Susan Katz'.\n",
    "- Wordcloud of all important words used in 'Susan Katz' reviews on amazon.\n",
    "- Number of distinct products reviewed by 'Susan Katz' on amazon.\n",
    "- Products reviewed by 'Susan Katz'.\n",
    "- Popular sub-category for 'Susan Katz'.\n",
    "- Price range in which 'Susan Katz' shops.\n",
    "-------------------\n",
    "#### Reviewer with maximum number of reviews.\n",
    "- Cleaning(Data Processing) was performed on 'ReviewSample.json' file and importing the data as pandas DataFrame.\n",
    "- Grouped on 'Reviewer_ID' and getting the count of reviews.\n",
    "- Sorted in Descending order of 'No_Of_Reviews'\n",
    "- Took Point_of_Interest DataFrame to .csv file\n",
    " - (path : '../Analysis/Analysis_3/Most_Reviews.csv')\n",
    "\n",
    "#### Distribution of reviews for 'Susan Katz' based on overall rating (reviewer_id : A1RRMZKOMZ2M7J).\n",
    "- Only took those review which is posted by 'SUSAN KATZ'.\n",
    "- Created a function 'ReviewCategory()' to give positive, negative and neutral status based on Overall Rating.\n",
    " - score >= 4 then positive\n",
    " - score <= 2 & score > 0 then negative\n",
    " - score =3 then neutral\n",
    "- Calling function 'ReviewCategory()' for each row of DataFrame column 'Rating'.\n",
    "- Grouped on 'Category' which we got in previous step and getting the count of reviews.\n",
    "- Bar Plot for Category V/S Count.\n",
    "<img src=\"../Analysis/Analysis_1/Category Vs Count.png\">\n",
    "\n",
    "#### Distribution of reviews over the years for 'Susan Katz'.\n",
    "- Grouping on 'Year' which we got in previous step and getting the count of reviews.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_3/Yearly_Count.csv')\n",
    "- Bar Plot to get trend over the years for Reviews Written by 'SUSAN KATZ'\n",
    "<img src=\"../Analysis/Analysis_1/​Number of Reviews Over Years.png\">\n",
    "\n",
    "#### Percentage distribution of negative reviews for 'Susan Katz', since the count of reviews is dropping post year 2009.\n",
    "- Took the count of negative reviews over the years using 'Groupby'.\n",
    "- Merging 2 Dataframe for mapping and then calculating the Percentage of Negative reviews for each year.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_3/Negative_Review_Percentage.csv')\n",
    "- Bar Plot for Year V/S Negative Reviews Percentage\n",
    "<img src=\"../Analysis/Analysis_1/% of negative Reviews Over Years.png\">\n",
    "\n",
    "#### Lexical density distribution over the year for reviews written by 'Susan Katz'.\n",
    "- Lexical words include:\n",
    " - verbs (e.g. run, walk, sit)\n",
    " - nouns (e.g. dog, Susan, oil)\n",
    " - adjectives (e.g. red, happy, cold)\n",
    " - adverbs (e.g. very, carefully, yesterday)\n",
    "- Created a function 'LexicalDensity(text)' to calculate Lexical Density of a content.\n",
    " - Steps involved are as follows:-\n",
    "  - Step 1 :- Converting the content into Lowercase.\n",
    "  - Step 2 :- Using nltk.tokenize to get words from the content.\n",
    "  - Step 3 :- Storing the total word count.\n",
    "  - Step 4 :- Using string.punctuation to get rid of punctuations.\n",
    "  - Step 5 :- Using stopwords from nltk.corpus to get rid of stopwords.\n",
    "  - Step 6 :- tagging of Words and taking count of words which has tags starting from (\"NN\",\"JJ\",\"VB\",\"RB\") which represents Nouns, Adjectives, Verbs and Adverbs respectively, will be the lexical count.\n",
    "  - Step 7 :- Finally; (lexical count/total count)*100.\n",
    "- Called Function 'LexicalDensity()' for each row of DataFrame.\n",
    "- Grouped on 'Year' and getting the average Lexical Density of reviews.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_3/Lexical_Density.csv')\n",
    "- Bar Plot for Year V/S Lexical Density\n",
    "<img src=\"../Analysis/Analysis_1/Lexical Density.png\">\n",
    "\n",
    "#### Wordcloud of all important words used in 'Susan Katz' reviews on amazon.\n",
    "- To Generate a word corpus following steps are performed inside the function 'create_Word_Corpus(df)'\n",
    " - Step 1 :- Iterating over the 'summary' section of reviews such that we only get important content of a review.\n",
    " - Step 2 :- Converting the content into Lowercase.\n",
    " - Step 3 :- Using nltk.tokenize to get words from the content.\n",
    " - Step 4 :- Using string.punctuation to get rid of punctuations.\n",
    " - Step 5 :- Using stopwords from nltk.corpus to get rid of stopwords.\n",
    " - Step 6 :- tagging of Words using nltk and only allowing words with tag as (\"NN\",\"JJ\",\"VB\",\"RB\").\n",
    " - Step 7 :- Finally forming a word corpus and returning the word corpus.\n",
    "- Generated a WordCloud image\n",
    "<img src=\"../Analysis/Analysis_1/Important Words Cloud.png\">\n",
    "\n",
    "#### Number of distinct products reviewed by 'Susan Katz' on amazon.\n",
    "- Took the unique Asin from the reviews reviewed by 'Susan Katz' and returned the length.\n",
    "\n",
    "#### Products reviewed by 'Susan Katz'.\n",
    "- Cleaning(Data Processing) was performed on 'ProductSample.json' file and importing the data as pandas DataFrame.\n",
    "- Mapping 'Product_dataset' with 'POI' to get the products reviewed by 'Susan Katz'\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_3/Products_Reviewed.csv')\n",
    " \n",
    "####  Popular sub-category for 'Susan Katz'.\n",
    "- Creating list of products reviewed by 'Susan Katz'\n",
    "- Created a Function 'make_flat(arr)' to make multilevel list values flat which was used to get sub-categories from multilevel list.\n",
    "- Taking the sub-category of each Asin reviewed by 'Susan Katz'.\n",
    "- Counting the Occurences and taking top 5 out of it.\n",
    "- Took Data to .csv file\n",
    " - (path : '../Analysis/Analysis_3/Popular_Sub-Category.csv')\n",
    " \n",
    "#### Price range in which 'Susan Katz' shops.\n",
    "- Took min, max and mean price of all the products by using aggregation function on data frame column 'Price'.\n",
    "\n",
    "## CONCLUSION OF ANALYSIS 3:-\n",
    "- 'Susan Katz' (reviewer_id : A1RRMZKOMZ2M7J) reviewed the maximumn number of products i.e. 180.\n",
    "- Susan was only 50 % of the times happy with products shopped on Amazon\n",
    "<pre>\n",
    "\n",
    "| Category | Count   |\n",
    "|------|------|\n",
    "|   neg  | 38|\n",
    "|   neu  | 51|\n",
    "|   pos  | 91|\n",
    "\n",
    "</pre>\n",
    "\n",
    "- Number of reviews were droping for 'Susan Katz' after 2009.\n",
    "- The reason why rating for 'Susan Katz' were dropping because Susan was not happy with maximum products she shopped i.e. because the negative review count had increased for every year after 2009.\n",
    "- The Average lexical density for 'Susan Katz' has always been under 40% i.e. 'Susan Katz' writting used to lack the important words.\n",
    "- Most popular words used in 'Susan Katz' content were shoes, color, fit, heels, watch and etc.\n",
    "- Number of distinct products reviewed by 'Susan Katz' on amazon is 180.\n",
    "- Popular Category in which 'Susan Katz' were Jewelry, Novelty, Costumes & More\n",
    "- 'Susan Katz' shopping Price Range\n",
    " - Minimum: 6.99\n",
    " - Maximum: 249.99\n",
    " - Average: 66.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 4 : 'BUNDLE' OR 'BOUGHT-TOGETHER' BASED ANALYSIS.\n",
    "- Check for the popular bundle (quantity in a bundle).\n",
    "- Top 10 Popular brands which sells Pack of 2 and 5, as they are the popular bundles.\n",
    "- Top 10 Popular Sub-Category with Pack of 2 and 5.\n",
    "- Checking for number of products the brand 'Rubie's Costume Co' has listed on Amazon since it has highest number of bundle in pack 2 and 5.\n",
    "- Minimum, Maximum and Average Selling Price of prodcts sold by the Brand 'Rubie's Costume Co'.\n",
    "- Top 10 Highest selling product in 'Clothing' Category for Brand 'Rubie's Costume Co'.\n",
    "- Top 10 most viewed product for brand 'Rubie's Costume Co'.\n",
    "-----------\n",
    "\n",
    "#### Check for the popular bundle (quantity in a bundle).\n",
    "- Cleaning(Data Processing) was performed on 'ProductSample.json' file and importing the data as pandas DataFrame.\n",
    "- Got numerical values for 'Number_Of_Pack' and etc from 'ProductSample.json'.\n",
    "- Grouped by Number of Pack and getting their respective count.\n",
    "- Took the data into .csv file\n",
    " - (path : '../Analysis/Analysis_4/Popular_Bundle.csv')\n",
    "- Bar Chart was plotted for Number of Packs \n",
    "<img src=\"../Analysis/Analysis_1/Popular Bundle.png\">\n",
    "\n",
    "#### Top 10 Popular brands which sells Pack of 2 and 5, as they are the popular bundles.\n",
    "- Got all the asin for Pack 2 and 5 and stored in a list 'list_Pack2_5' since they have the highest number of counts\n",
    "- Got the brand name of those asin which were present in the list 'list_Pack2_5'.\n",
    "- Removed the rows which does not have brand name\n",
    "- Counted the occurence of brand name and giving the top 10 brands.\n",
    "- Took the data into .csv file\n",
    " - (path : '../Analysis/Analysis_4/Popular_Brand.csv')\n",
    "- Bar Chart was plotted for Popular brands.\n",
    "<img src=\"../Analysis/Analysis_1/Popular Brand.png\">\n",
    "\n",
    "#### Top 10 Popular Sub-Category with Pack of 2 and 5.\n",
    "- Got all the asin for Pack 2 and 5 and stored in a list 'list_Pack2_5'\n",
    "- Created a Function 'make_flat(arr)' to make multilevel list values flat which was used to get sub-categories from multilevel list.\n",
    "- Got the category of those asin which was present in the list 'list_Pack2_5'.\n",
    "- Counted the occurence of Sub-Category and giving the top 10 Sub-Category.\n",
    "\n",
    "#### Checking for number of products the brand 'Rubie's Costume Co' has listed on Amazon.\n",
    "- Got all the products which has brand name 'Rubie's Costume Co'\n",
    "- Took the total count of the products.\n",
    "\n",
    "#### Minimum, Maximum and Average Selling Price of prodcts sold by the Brand 'Rubie's Costume Co'.\n",
    "- Took min, max and mean price of all the products by using aggregation function on data frame column 'Price'. \n",
    "\n",
    "#### Top 10 Highest selling product in 'Clothing' Category for Brand 'Rubie's Costume Co'.\n",
    "- Took all the Asin, SalesRank and etc. whose brand is 'RUBIE'S COSTUME CO' from ProductSample.json.\n",
    "- Created a Data frame for above.\n",
    "- Sorted DataFrame based on sales Rank.\n",
    "- Calculated Average selling price for top 10 products.\n",
    "- Took the data into .csv file\n",
    " - (path : '../Analysis/Analysis_4/Popular_Product.csv'). \n",
    "- Bar Plot\n",
    "<img src=\"../Analysis/Analysis_1/Top 10(SalesRank).png\">\n",
    "\n",
    "#### Top 10 most viewed product for brand 'Rubie's Costume Co'.\n",
    "- From all the Asin getting all the Asin present in 'also_viewed' section of json file.\n",
    "- Counting the Occurence of Asin for brand Rubie's Costume Co.\n",
    "- Creating a DataFrame with Asin and its Views.\n",
    "- Getting products of brand Rubie's Costume Co.\n",
    "- Merging the 2 DataFrames 'views_dataset' and 'view_prod_dataset' such that only the Rubie's Costume Co. products from 'view_prod_dataset' gets mapped. Inner type merge was performed to get only mapped product with Rubie's Costume Co.\n",
    "- Sorting the DataFrame based column 'Views'\n",
    "- Took the data into .csv file\n",
    " - (path : '../Analysis/Analysis_4/Most_Viewed_Product.csv')\n",
    "- Took min, max and mean price of Top 10 products by using aggregation function on data frame column 'Price'\n",
    "<img src=\"../Analysis/Analysis_1/Top 10(Views).png\">\n",
    "\n",
    "## CONCLUSION OF ANALYSIS 4:-\n",
    "- Pack of 2 and 5 found to be the most popular bundled product.\n",
    "- 'Rubie's Costume Co' found to be the most popular brand to sell Pack of 2 and 5.\n",
    "- Women, Novelty Costumes & More, Novelty, etc. are the popular sub-category in 'Clothing shoes and Jewellery' on Amazon.\n",
    "- 'Rubie's Costume Co' has 2175 products listed on Amazon.\n",
    "- 'Rubie's Costume Co' Selling Price Range\n",
    " - Minimum: 0.66\n",
    " - Maximum: 783.01\n",
    " - Average: 20.43\n",
    "- Popular products for 'Rubie's Costume Co' were in the price range 5-15. such as \n",
    " - DC Comics Boys Action Trio Superhero Costume Set\n",
    " - The Dark Knight Rises Batman Child Costume Kit\n",
    " - Star Wars Clone Wars Ahsoka Lightsaber, etc.\n",
    "- 'Rubie's Costume Co' Selling Price Range \n",
    " - Minimum: 4.95\n",
    " - Maximum: 12.99\n",
    " - Average: 7.24\n",
    " - Most viewed products for 'Rubie's Costume Co' were also in the price range 5-15, this confirms the popular product data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS 5 : RECOMMENDER SYSTEM FOR BRAND RUBIE'S COSTUME CO. \n",
    "- Collaborative filtering algorithms is used to get the recomendations.\n",
    "- The Recommender System will take the 'Product Name' and based on the correlation factor will give output as list of products which will be a suggestion or recommendation.\n",
    "- Suppose product name 'A' act as input parameter i.e. If a user buy product 'A' so based on that it will output the product highly correlated to it.\n",
    "-----------------------------------------\n",
    "\n",
    "- Cleaning(Data Processing) was performed on 'ProductSample.json' file and importing the data as pandas DataFrame.\n",
    "- Gat all the distinct product Asin of brand 'Rubie's Costume Co.' in list.\n",
    "- Cleaning(Data Processing) was performed on 'ReviewSample.json' file and importing the data as pandas DataFrame.\n",
    "- Created a DataFrame 'Working_dataset' which has products only from brand \"RUBIE'S COSTUME CO.\".\n",
    "- Performed a merge of 'Working_dataset' and 'Product_dataset' to get all the required details together for building the Recommender system.\n",
    "- Took only the required columns and created a pivot table with index as 'Reviewer_ID' , columns as 'Title' and values as 'Rating'.\n",
    "- Created a function 'pearson(x1,x2)'. \n",
    " - Function to find the pearson correlation between two columns or products.\n",
    " - Will produce result between -1 to 1.\n",
    " - Function will be used within the recommender function 'get_recommendations()'.\n",
    "- Created a function 'get_recommendations(product_id,M,num)'. \n",
    " - Function to recommend the product based on correlation between them.\n",
    " - Takes 3 parameters 'Product Name', 'Model' and 'Number of Recomendations'\n",
    " - Will return a list in descending order of correlation and the list size depends on the input given for Number of Recomendations.\n",
    "- Created a function 'escape(t)'. \n",
    " - Function to replace all the html escape characters to respective characters.\n",
    "- Calling the recommender System by making a function call to 'get_recommendations('300 Movie Spartan Shield',Model,5)'.\n",
    " - '300 Movie Spartan Shield' is the product name pass to the function i.e. if person buys '300 Movie Spartan Shield' what else can be recommended to him/her.\n",
    " - 'Model' is passed for correlation calculation. Model is a pivot table created previously.\n",
    " - '5' is the maximum number of recommendation a function can return if there is some correlation.\n",
    " - Quantifying the correlation can be done by using correlation value given in the output.\n",
    "- Taking recommendation into DataFrame for Tabular represtation.\n",
    " - Takng only those values whose correlation is greater than 0.\n",
    "- Took all the recommendations into .csv file\n",
    " - (path : '../Analysis/Analysis_5/Recommendation.csv')\n",
    " \n",
    "## CONCLUSION OF ANALYSIS 5:\n",
    "- When '300 Movie Spartan Shield' is passed to recommender system.\n",
    "- Output:  - <pre>\n",
    " \n",
    "| Product Title | Correlation   |\n",
    "|------|------|\n",
    "|   300 Movie Spartan Deluxe Vinyl Helmet  | 0.223277|\n",
    "|   Toynk Toys - 300- Spartan Sword  | 0.069275|\n",
    "\n",
    "</pre>\n",
    "    - Above given table is recomendation for '300 Movie Spartan Shield'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "- Image-based recommendations on styles and substitutes J. McAuley, C. Targett, J. Shi, A. van den Hengel SIGIR, 2015\n",
    "- Inferring networks of substitutable and complementary products J. McAuley, R. Pandey, J. Leskovec Knowledge Discovery and Data Mining, 2015"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
